{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation using Pytorch\n",
    "\n",
    "*Following are curated as self study notes from the readings of online book [Deep Dive into Deep Learning](https://d2l.ai/chapter_preliminaries/ndarray.html). Alongside with my personal notes wherever I needed more explaination to keep for later reference.*\n",
    "\n",
    "**A tensor represents a (possibly multi-dimensional) array of numerical values**\n",
    "\n",
    "- Package to import `torch`\n",
    "- Tensor 1 Axes ~ Vector\n",
    "- Tensor 2 Axes ~ Matrix\n",
    "- Tensor With K axes ~ object as a Kth order tensor \n",
    "- Unless otherwise specified, new tensors are stored in main memory and designated for CPU-based computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(12, dtype = torch.float32)\n",
    "x # Note - 0 is included, 12 is excluded, spaced by 1, prints a series upto 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel() # Size of the elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape #a tensorâ€™s shape (the length along each axis) by inspecting its shape attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = x.reshape(3, 4) #change the shape of a tensor without altering its size or values, by invoking reshape\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2, 3, 4)) #Practitioners often need to work with tensors initialized to contain all zeros or ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2, 3, 4)) #we can create a tensor with all ones by invoking ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0795, -0.2561, -0.8737,  0.5461],\n",
       "         [ 0.5143,  1.1183, -0.4634,  0.7963],\n",
       "         [-1.2618, -1.2886, -0.3583, -0.4733]],\n",
       "\n",
       "        [[-0.9096, -2.6475, -0.0294,  0.7994],\n",
       "         [-0.6947, -0.4350,  0.6657, -0.4991],\n",
       "         [ 0.5117,  0.7535,  1.4867, -0.2024]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5424, -1.1933,  1.6353],\n",
       "        [ 0.8635, -0.1641,  0.0671]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.randn() and difference between `torch.randn((2, 3, 4))` and `torch.randn(2, 3)`\n",
    "\n",
    "`torch.randn()` is a function used to generate random numbers from a normal distribution with a mean of 0 and a standard deviation of 1. The function generates random numbers based on the shape specified in the input arguments. Let's break down the differences between `torch.randn((2, 3, 4))` and `torch.randn(2, 3)`:\n",
    "\n",
    "1. `torch.randn((2, 3, 4))`:\n",
    "   - This syntax creates a 3-dimensional tensor with a shape of `(2, 3, 4)`.\n",
    "   - The function generates random numbers from a standard normal distribution (mean=0, std=1) and arranges them into a tensor with the specified shape.\n",
    "\n",
    "   For example:\n",
    "   ```\n",
    "   tensor([[[-0.1473,  1.0817,  0.4241, -0.2850],\n",
    "            [ 0.2577,  1.6705,  0.1176,  0.1603],\n",
    "            [-1.3135, -0.4098, -1.8831, -0.7269]],\n",
    "\n",
    "           [[-1.5825, -0.2327,  0.2387, -0.4960],\n",
    "            [ 1.4255, -0.4050, -1.2385,  0.6178],\n",
    "            [ 0.0446,  0.5943,  1.8471,  1.0647]]])\n",
    "   ```\n",
    "\n",
    "2. `torch.randn(2, 3)`:\n",
    "   - This syntax creates a 2-dimensional tensor with a shape of `(2, 3)`.\n",
    "   - The function generates random numbers from a standard normal distribution (mean=0, std=1) and arranges them into a 2D tensor with the specified shape.\n",
    "\n",
    "   For example:\n",
    "   ```\n",
    "   tensor([[-0.5634, -1.1082,  1.2536],\n",
    "           [ 0.7942,  0.0482, -0.2921]])\n",
    "   ```\n",
    "\n",
    "In summary, the key difference between the two is the shape of the resulting tensor. The first call, `torch.randn((2, 3, 4))`, generates a 3D tensor with dimensions (2, 3, 4), while the second call, `torch.randn(2, 3)`, generates a 2D tensor with dimensions (2, 3). The numbers within the tensors are random samples from the standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4],\n",
       "        [5, 6, 7],\n",
       "        [8, 9, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2, 3, 4], [5, 6, 7], [8, 9, 0]]) #construct tensors by supplying the exact values for each element by supplying (possibly nested) Python list(s) containing numerical literals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
